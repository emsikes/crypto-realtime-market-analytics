{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ee3ab98-d714-4f3a-895a-c0426c4bf4e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer: Kafka Ingestion\n",
    "\n",
    "Reads raw crypto price data from Confluent Cloud and lands it in Delta Lake.\n",
    "\n",
    "- **Source:** Kafka topic 'crypto-prices-raw'\n",
    "- **Target:** 'crypto_analytics.bronze.raw_prices'\n",
    "- **Mode:** Structured Streaming (append-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c7b8529-c5a3-4b57-aba1-39b624d68e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Kafka connection config\n",
    "KAFKA_TOPIC = \"crypto-prices-raw\"\n",
    "BRONZE_TABLE = \"crypto_analytics.bronze.raw_prices\"\n",
    "CHECKPOINT_PATH = \"abfss://demo@deacourseextdlst.dfs.core.windows.net/crypto_analytics/_checkpoints/bronze_raw_prices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2813675-db10-4a1f-ba0e-aa6f8a64c3ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve Kafka credentials from secrets scope\n",
    "kafka_bootstrap = dbutils.secrets.get(scope=\"crypto-pipeline\", key=\"CONFLUENT_BOOTSTRAP_SERVERS\")\n",
    "kafka_api_key = dbutils.secrets.get(scope=\"crypto-pipeline\", key=\"CONFLUENT_API_KEY\")\n",
    "kafka_api_secret = dbutils.secrets.get(scope=\"crypto-pipeline\", key=\"CONFLUENT_API_SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f7d46e7-a3af-428c-b86a-49a9c876b750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Kafka config options used below\n",
    "\n",
    "- bootstrap.servers         Confluent Cloud broker address\n",
    "- security.protocol         Encrypted connection (required for Confluent Cloud)\n",
    "- sasl.mechanism            Authentication type\n",
    "- sasl.jaas.config          Credentials in Java auth format (Spark uses Java Kafka client)\n",
    "- subscribe                 Which topic to read\n",
    "- startingOffsets           earliest = read all existing messages; latest = only new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b897823-97e0-4158-b262-8efa14a1cfc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build Kafka connection configuration\n",
    "kafka_options = {\n",
    "    \"kafka.bootstrap.servers\": kafka_bootstrap,\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\",\n",
    "    \"kafka.sasl.jaas.config\": f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{kafka_api_key}\" password=\"{kafka_api_secret}\";',\n",
    "    \"subscribe\": KAFKA_TOPIC,\n",
    "    \"startingOffsets\": \"earliest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93ce9786-31d5-498d-8136-7bcff678ae99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read stream from Kafka\n",
    "raw_stream = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .options(**kafka_options)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "raw_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183c5751-b5bd-4fa6-bfa8-50a17c2fff54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform Kafka messages for Bronze table\n",
    "# - Cast binary values to string\n",
    "# - Leave values in json format for bronze tier, will parse in silver\n",
    "# - Keep Kafka metadata for lineage\n",
    "# - Add timestamp for ingestion\n",
    "from pyspark.sql.functions import col, cast, current_timestamp\n",
    "\n",
    "bronze_stream = (\n",
    "    raw_stream\n",
    "    .selectExpr(\n",
    "        \"CAST(key AS STRING) as message_key\",\n",
    "        \"CAST(value AS STRING) as raw_json\",\n",
    "        \"topic\",\n",
    "        \"partition\",\n",
    "        \"offset\",\n",
    "        \"timestamp as kafka_timestamp\"\n",
    "    )\n",
    "    .withColumn(\"bronze_ingested_at\", current_timestamp())\n",
    ")\n",
    "\n",
    "bronze_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e518c3-0fa0-4875-9f98-99ac25294610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write stream to Bronze table\n",
    "bronze_query = (\n",
    "    bronze_stream\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_PATH)\n",
    "    .toTable(BRONZE_TABLE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a84ea98b-bf58-4df7-a06d-d0eaca630e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as row_count FROM crypto_analytics.bronze.raw_prices\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "513b3c75-1444-43df-94a7-799c2a8ae720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        message_key,\n",
    "        raw_json,\n",
    "        kafka_timestamp,\n",
    "        bronze_ingested_at\n",
    "    FROM\n",
    "        crypto_analytics.bronze.raw_prices\n",
    "    LIMIT 5          \n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5cab135-2154-4589-9492-e066a9463946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c330c3f-9258-49d6-8e26-c7863694b23f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_bronze_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
